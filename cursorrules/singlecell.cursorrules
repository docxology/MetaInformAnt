# Single-Cell Module Rules (`metainformant.singlecell`)

## Purpose
Single-cell transcriptomic analysis: quality control, normalization, dimensionality reduction, clustering, and trajectory analysis.

## Dependencies
- **Required**: `core`, `rna` (expression data), `ml.dimensionality`
- **Optional**: `scanpy`, `anndata`

## Source Structure
```
src/metainformant/singlecell/
├── analysis/
│   ├── clustering.py, dimensionality.py, trajectory.py
├── data/
│   ├── integration.py, preprocessing.py
└── visualization/
    └── visualization.py
```

## Package Management
- **ALWAYS use `uv`** for all Python package management and environment operations
- Install optional dependencies: `uv add scanpy anndata`
- Use `uv run` to execute commands: `uv run pytest`, `uv run metainformant singlecell --help`
- **NEVER use `pip` directly**

## Key Submodules

### Preprocessing
- Quality control metrics
- Cell and gene filtering
- Normalization (log-normalization, scaling)

### Dimensionality
- Principal Component Analysis (PCA)
- t-SNE
- UMAP

**Patterns**:
```python
from metainformant.singlecell.analysis import dimensionality
from metainformant.ml.features import dimensionality as ml_dimensionality

# Use shared dimensionality reduction
pca_result = ml_dimensionality.pca(expression_matrix, n_components=50)
```

### Clustering
- Leiden algorithm
- Louvain algorithm
- Community detection

### Trajectory (`trajectory`)
- Pseudotime analysis
- Trajectory inference
- Branch point detection

**Patterns**:
```python
from metainformant.singlecell.analysis import trajectory

data = trajectory.compute_pseudotime(data, root_cells=0, method="diffusion")
traj_result = trajectory.trajectory_analysis(data)
```

### Integration (`integration`)
- Multi-sample batch correction
- Canonical correlation analysis (CCA)
- Mutual nearest neighbors (MNN) correction
- Harmony batch correction
- Data integration quality assessment

**Patterns**:
```python
from metainformant.singlecell.data import integration

# Integrate multiple samples
integrated = integration.integrate_datasets([sample1_data, sample2_data, sample3_data])

# Harmony batch correction
corrected = integration.harmony_integration(integrated, batch_key="batch")

# Alternative: Combat batch correction
corrected = integration.batch_correction(integrated, batch_key="batch", method="combat")
```

### Visualization (`visualization`)
- QC metrics visualization
- Dimensionality reduction plots (UMAP, t-SNE)
- Gene expression overlays
- Trajectory visualizations
- Cluster annotation plots

**Patterns**:
```python
from metainformant.singlecell import (
    plot_qc_metrics,
    plot_dimensionality_reduction,
    plot_gene_expression,
    plot_clusters
)

# Create visualizations
fig = plot_qc_metrics(data)
fig = plot_dimensionality_reduction(data, method="umap", color_by="cluster")
fig = plot_gene_expression(data, gene="GENE1")
fig = plot_clusters(data, cluster_key="cluster")
```

## Patterns

### I/O Operations
- **CRITICAL**: Always use `metainformant.core.io` for JSON/CSV/TSV operations
- Never use direct `import json` or `import csv`

**Pattern**:
```python
from metainformant.core import io

# Save analysis results
io.dump_json(results, "output/singlecell/analysis/clustering.json")
io.write_csv(df, "output/singlecell/analysis/markers.csv")
```

### Path Handling
- Always use `metainformant.core.paths` utilities for path operations
- Always resolve and validate paths using `paths.expand_and_resolve()` and `paths.is_within()`

**Pattern**:
```python
from metainformant.core import paths

# Expand and resolve paths
output_path = paths.expand_and_resolve("output/singlecell/analysis/")
```

### Type Hints
- Comprehensive type hints throughout
- Use `from __future__ import annotations` for forward references
- Union types: `str | Path | None`

### scanpy Integration
- Use `scanpy` when available
- Fallback to scikit-learn implementations
- Handle `AnnData` objects when available

**Pattern**:
```python
try:
    import scanpy as sc
    SCANPY_AVAILABLE = True
except ImportError:
    SCANPY_AVAILABLE = False

def normalize_data(data):
    if SCANPY_AVAILABLE:
        return sc.pp.normalize_total(data)
    else:
        # Fallback implementation
        return normalize_manual(data)
```

### AnnData Objects
- Support `AnnData` format when available
- Convert to/from standard formats (pandas, numpy)
- Preserve metadata in AnnData objects

### Output Paths
- Base: `output/singlecell/<analysis>/`
- Preprocessing: `output/singlecell/<analysis>/preprocessing/`
- Clustering: `output/singlecell/<analysis>/clustering/`
- Trajectory: `output/singlecell/<analysis>/trajectory/`
- Integration: `output/singlecell/<analysis>/integration/`
- Visualizations: `output/singlecell/<analysis>/plots/`

### Dimensionality Reduction
- Use `ml.dimensionality` for shared implementations
- Support both scanpy and scikit-learn APIs
- Return consistent data structures

## Configuration

- No module-specific config (uses core config)
- Output paths default to `output/singlecell/`
- Environment prefix: `SC_` (e.g., `SC_THREADS`, `SC_WORK_DIR`)

## Integration

- **Uses**: `rna` (expression data), `ml.dimensionality`
- **Used by**: `multiomics` (single-cell omics integration), `information` (single-cell information analysis)
- **External**: `scanpy`, `anndata` when available

## Reference

See main `.cursorrules` for:
- Common directory structure and path handling
- Configuration patterns with env overrides
- Testing policy (NO_MOCKING_POLICY)
- Import patterns and code style
- Documentation guidelines

## Testing

- **STRICTLY NO MOCKING**: Test real implementations only (see main `.cursorrules` NO_MOCKING_POLICY)
- Skip tests if scanpy/anndata unavailable using `@pytest.mark.external_tool`
- Test with real expression matrices from `data/`
- Write test outputs to `output/singlecell/test/` using `tmp_path` fixture
- No mocks, fakes, or stubs - use real computations


