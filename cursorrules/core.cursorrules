# Core Module Rules (`metainformant.core`)

## Purpose
Shared utilities across all domains. Foundation for all other modules.

## Dependencies
- **Required**: Standard library only
- **Optional**: Handled defensively (try/except imports)

## Package Management
- **ALWAYS use `uv`** for all Python package management and environment operations
- Use `uv venv` to create virtual environments
- Use `uv pip install` for installing packages
- Use `uv run` to execute commands in the project environment
- Use `uv sync` to sync dependencies from `pyproject.toml` and `uv.lock`
- Use `uv add <package>` to add new dependencies
- Use `uv remove <package>` to remove dependencies
- **NEVER use `pip`, `pip3`, `python -m pip`, or `python3 -m pip` directly**

## Key Submodules

### Configuration (`config`)
- Configuration loading from YAML/TOML/JSON
- Environment variable overrides
- Type-safe config classes
- Database configuration (PostgreSQL)

**Patterns**:
```python
from metainformant.core.config import load_mapping_from_file, apply_env_overrides

raw = load_mapping_from_file("config/file.yaml")
config = apply_env_overrides(raw, prefix="MODULE")
```

### I/O (`io`)
- JSON/JSONL/CSV/TSV operations
- Gzip-aware file operations
- Atomic writes for data integrity
- Automatic directory creation

**CRITICAL**: All modules MUST use `metainformant.core.io` for file I/O. Never use direct `import json` or `import csv` in domain modules.

**Patterns**:
```python
from metainformant.core import io

# Reading
data = io.load_json("data/file.json")
records = list(io.read_jsonl("data/records.jsonl"))
df = io.load_csv("data/table.csv")

# Writing (creates parent dirs automatically)
io.dump_json(data, "output/result.json")
io.write_csv(df, "output/table.csv")
io.write_jsonl(records, "output/records.jsonl")

# Gzip-aware operations
with io.open_text_auto("data/large_file.txt.gz") as f:
    content = f.read()
```

**❌ PROHIBITED**:
```python
import json  # ❌ WRONG - use metainformant.core.io instead
import csv   # ❌ WRONG - use metainformant.core.io instead

data = json.load(f)  # ❌ WRONG
json.dump(data, f)   # ❌ WRONG
```

### Paths (`paths`)
- Path expansion and resolution
- Containment checks (security)
- Safe path validation

**Patterns**:
```python
from metainformant.core import paths
from pathlib import Path

# Expand and resolve
path = paths.expand_and_resolve("~/data/file.txt")

# Security check
if paths.is_within(user_path, base_dir):
    # Safe to use
    pass
```

### Logging (`logging`)
- Structured logging with consistent formatting
- Module-specific loggers

**Patterns**:
```python
from metainformant.core.logging import get_logger

logger = get_logger(__name__)
logger.info("Operation started")
logger.error("Error occurred", exc_info=True)
```

### Cache (`cache`)
- JSON-based caching with TTL
- Cache under `output/` directory

## Output Paths

- Core outputs: `output/core/`
- Cache: `output/core/cache/`
- Logs: `output/core/logs/`

### Parallel (`parallel`)
- Thread-based parallel processing
- Preserves order of results

### Errors (`errors`)
- Custom error types
- Biological context in error messages

### Progress (`progress`)
- Progress tracking utilities
- Integration with long-running operations

### Validation (`validation`)
- Data validation utilities
- Type checking and format validation

### Workflow (`workflow`)
- Workflow orchestration functions
- Config-based workflow execution

### Database (`db`)
- Optional database client helpers (PostgreSQL)
- Database connection management
- Query utilities

### Disk (`disk`)
- Disk space and file system utilities
- Disk usage monitoring
- File system operations

### Hash (`hash`)
- Content and file hashing functions
- Checksum generation
- File integrity verification

### Discovery (`discovery`)
- Symbolic mapping and context discovery utilities
- Code discovery and analysis
- Symbol resolution

### Symbols (`symbols`)
- Symbol indexing and cross-referencing utilities
- Symbol management
- Cross-module symbol resolution

### Text (`text`)
- Text normalization and manipulation utilities
- Text processing functions
- String manipulation helpers

## Patterns

### Defensive Imports
```python
try:
    import optional_library
except ImportError:
    optional_library = None  # type: ignore

def function():
    if optional_library is None:
        raise ImportError("optional_library required")
    # Use library
```

### Pure Functions
- Prefer pure functions with minimal side effects
- Functions should be testable in isolation
- Side effects limited to I/O operations

### Error Handling
- Use `metainformant.core.errors` types
- Provide clear, actionable error messages
- Include biological context when relevant

### Type Hints
- Comprehensive type hints throughout
- Use `from __future__ import annotations` for forward references
- Union types: `str | Path | None`

## Testing

- Core utilities must have comprehensive tests
- **STRICTLY NO MOCKING**: Test real implementations only (see main `.cursorrules` NO_MOCKING_POLICY)
- Use `tmp_path` fixture for test outputs
- Write test artifacts to `output/` only
- No `unittest.mock`, `@patch`, `MagicMock`, or function replacement
- Use real implementations with graceful skipping for unavailable dependencies

## Documentation

- Each submodule should have clear docstrings
- Examples in docstrings should use `output/` paths
- Document optional dependencies and their availability
- Reference module-specific cursorrules for domain patterns

## Integration with Other Modules

All other modules depend on `core` utilities:
- Import core utilities: `from metainformant.core import io, paths, logging, config`
- Use core utilities for all I/O, logging, and path operations
- Do not reimplement core functionality in domain modules
- **NEVER** use direct `json` or `csv` imports - always use `metainformant.core.io`
- **NEVER** use direct `Path()` manipulation without `metainformant.core.paths` utilities

## Reference

See main `.cursorrules` for:
- Common directory structure and path handling
- Configuration patterns with env overrides
- Testing policy (NO_MOCKING_POLICY)
- Import patterns and code style
- Documentation guidelines

