# ML Module Rules (`metainformant.ml`)

## Purpose
Machine learning for biological data: classification, regression, dimensionality reduction, feature selection, and model validation.

## Dependencies
- **Required**: `core`
- **Optional**: `scikit-learn`, `xgboost`, `lightgbm`

## Source Structure
```
src/metainformant/ml/
├── evaluation/
│   └── validation.py
├── features/
│   ├── dimensionality.py, features.py
├── llm/
│   └── ollama/
│       ├── chains.py, client.py, config.py, prompts.py
└── models/
    ├── classification.py, regression.py
```

## Package Management
- **ALWAYS use `uv`** for all Python package management and environment operations
- Install optional dependencies: `uv add scikit-learn xgboost lightgbm`
- Use `uv run` to execute commands: `uv run pytest`, `uv run metainformant ml --help`
- **NEVER use `pip` directly**

## Key Submodules

### Classification (`classification`)
- Classification models
- Support vector machines
- Random forests
- Gradient boosting

### Regression (`regression`)
- Regression models
- Linear regression
- Ridge/Lasso regression
- Used by GWAS module

**Patterns**:
```python
from metainformant.ml.models import regression

model = regression.fit_linear_model(
    X=features,
    y=phenotypes,
    covariates=covariates
)
predictions = model.predict(X_test)
```

### Dimensionality (`dimensionality`)
- Dimensionality reduction
- PCA, UMAP
- Shared across modules (single-cell, multi-omics)

**Patterns**:
```python
from metainformant.ml.features import dimensionality

pca_result = dimensionality.pca(
    data=expression_matrix,
    n_components=50
)
# Returns: transformed data and explained variance
```

### Features (`features`)
- Feature selection
- Feature importance scores
- Returns dictionaries with feature rankings

### Validation (`validation`)
- Cross-validation
- Model assessment
- Performance metrics

**Patterns**:
```python
from metainformant.ml.evaluation import validation

scores = validation.cross_validate(
    model=model,
    X=data,
    y=labels,
    cv=5
)
```

## Patterns

### I/O Operations
- **CRITICAL**: Always use `metainformant.core.io` for JSON/CSV/TSV operations
- Never use direct `import json` or `import csv`

**Pattern**:
```python
from metainformant.core import io

# Save model results
io.dump_json(results, "output/ml/models/model_results.json")
io.write_csv(df, "output/ml/predictions/predictions.csv")
io.dump_json(feature_importance, "output/ml/features/importance.json")
```

### Path Handling
- Always use `metainformant.core.paths` utilities for path operations
- Always resolve and validate paths using `paths.expand_and_resolve()` and `paths.is_within()`

**Pattern**:
```python
from metainformant.core import paths

# Expand and resolve paths
model_dir = paths.expand_and_resolve("output/ml/models/")
```

### Type Hints
- Comprehensive type hints throughout
- Use `from __future__ import annotations` for forward references
- Union types: `str | Path | None`

### scikit-learn API
- Follow scikit-learn API conventions
- Models support `fit()`, `predict()`, `predict_proba()` methods
- Return consistent data structures

### Feature Importance
- Return feature importance scores as dictionaries
- Include feature names and scores
- Support multiple importance metrics

### Model Validation
- Use `validation` module for cross-validation
- Report multiple performance metrics
- Support stratified cross-validation

### Output Paths
- Models: `output/ml/models/`
- Predictions: `output/ml/predictions/`
- Feature importance: `output/ml/features/`

## Configuration

- No module-specific config (uses core config)
- Output paths default to `output/ml/`
- Environment prefix: `ML_` (e.g., `ML_THREADS`, `ML_WORK_DIR`, `ML_MODEL_DIR`)

## Integration

- **Used by**: `gwas` (regression models), `singlecell` (dimensionality reduction), `life_events` (sequence models)

## Reference

See main `.cursorrules` for:
- Common directory structure and path handling
- Configuration patterns with env overrides
- Testing policy (NO_MOCKING_POLICY)
- Import patterns and code style
- Documentation guidelines

## Testing

- **STRICTLY NO MOCKING**: Test real implementations only (see main `.cursorrules` NO_MOCKING_POLICY)
- Test with real biological datasets from `data/`
- Write test outputs to `output/ml/test/` using `tmp_path` fixture
- Test model serialization/deserialization
- No mocks, fakes, or stubs - use real ML operations


