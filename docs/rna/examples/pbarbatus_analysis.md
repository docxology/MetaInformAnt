# Pogonomyrmex barbatus RNA-seq Pipeline - Complete Guide

**Date**: October 28, 2025  
**Species**: *Pogonomyrmex barbatus* (red harvester ant)  
**Tissue**: Brain  
**Directory**: `output/amalgkit/pbarbatus/`

---

## 📁 Directory Structure

```
output/amalgkit/pbarbatus/
├── work/
│   ├── metadata/
│   │   └── metadata.tsv              # 83 samples discovered from NCBI SRA
│   ├── index/
│   │   └── Pogonomyrmex_barbatus.idx # Kallisto index (20.3MB, ready to use)
│   ├── fasta/
│   │   └── Pogonomyrmex_barbatus.fasta # Transcriptome reference (51.3MB)
│   └── quant/
│       ├── SRR14740487/              # Quantified sample 1
│       │   └── abundance.tsv         # Gene expression values (826KB)
│       └── SRR14740488/              # Quantified sample 2
│           └── abundance.tsv         # Gene expression values (828KB)
├── genome/                           # P. barbatus genome reference
├── fastq/                            # Downloaded FASTQ files (cleaned after quant)
├── logs/                             # Pipeline logs
└── merged/                           # Merged expression matrix (after all samples)
```

---

## 📊 Current Status

| Component | Status | Details |
|-----------|--------|---------|
| **Metadata** | ✅ Complete | 83 samples from NCBI SRA |
| **Genome Reference** | ✅ Downloaded | GCF_000187915.1 |
| **Transcriptome** | ✅ Prepared | 20,672 transcripts |
| **Kallisto Index** | ✅ Built | Ready for quantification |
| **Samples Downloaded** | 2/83 (2.4%) | SRR14740487, SRR14740488 |
| **Samples Quantified** | 2/83 (2.4%) | ~90% expression rate |
| **Expression Matrix** | ⏹️ Pending | Need all 83 samples |

---

## 🎯 Completed Samples

### SRR14740487 (Brain Sample 1)
```
Location:   output/amalgkit/pbarbatus/work/quant/SRR14740487/abundance.tsv
Transcripts: 20,672 total, 18,592 expressed (89.9%)
Reads:       26,078,116 processed, 16,838,576 mapped (64.6%)
Quality:     ✅ Excellent mapping and expression rates

Top 3 genes:
  1. XM_011631231.1 - TPM: 24,372.3
  2. XM_011648336.2 - TPM:  8,560.4
  3. XM_025219454.1 - TPM:  4,694.1
```

### SRR14740488 (Brain Sample 2)
```
Location:   output/amalgkit/pbarbatus/work/quant/SRR14740488/abundance.tsv
Transcripts: 20,672 total, 18,719 expressed (90.6%)
Reads:       27,085,159 processed, 17,828,830 mapped (65.8%)
Quality:     ✅ Excellent mapping and expression rates

Top 3 genes:
  1. XM_011631231.1 - TPM: 29,342.9
  2. XM_011632595.2 - TPM: 28,000.0
  3. XM_011648336.2 - TPM: 10,236.0
```

---

## 🚀 Processing Remaining Samples

### Method 1: Batch Processing (Recommended)

Process in batches of 10 to manage disk space (~45GB peak per batch):

```bash
cd /Users/4d/Documents/GitHub/metainformant

# For batch processing
PYTHONPATH=src python3 << 'EOF'
from pathlib import Path
from metainformant.rna import amalgkit

config_dir = Path("output/amalgkit/pbarbatus")
work_dir = config_dir / "work"

# Get list of unprocessed samples
import pandas as pd
metadata = pd.read_csv(work_dir / "metadata" / "metadata.tsv", sep='\t')
quant_dir = work_dir / "quant"
quantified = set(d.name for d in quant_dir.iterdir() if d.is_dir() and d.name.startswith('SRR'))
remaining = [run for run in metadata['run_accession'] if run not in quantified]

print(f"Remaining samples: {len(remaining)}")
print(f"Processing in batches of 10...")

# Process in batches
batch_size = 10
for i in range(0, len(remaining), batch_size):
    batch = remaining[i:i+batch_size]
    print(f"\nBatch {i//batch_size + 1}: Processing {len(batch)} samples")
    
    for run_id in batch:
        print(f"  Processing {run_id}...")
        
        # Download FASTQ (amalgkit will put in work/fastq/{run_id})
        # Quantify (uses existing index)
        # Clean up FASTQ after successful quantification
        
        # This will be implemented with amalgkit commands
        pass

EOF
```

### Method 2: Direct Kallisto (More Control)

```bash
cd /Users/4d/Documents/GitHub/metainformant

# Process each remaining sample
for run_id in SRR14740489 SRR14740490 ...; do
  echo "Processing $run_id..."
  
  # 1. Download FASTQ with amalgkit
  PYTHONPATH=src python3 -c "
from metainformant.rna import amalgkit
from pathlib import Path
config_dir = Path('output/amalgkit/pbarbatus')
work_dir = config_dir / 'work'

# Download this specific sample
# (amalgkit getfastq with batch parameter or filtered metadata)
"
  
  # 2. Quantify with kallisto
  kallisto quant \
    -i output/amalgkit/pbarbatus/work/index/Pogonomyrmex_barbatus.idx \
    -o output/amalgkit/pbarbatus/work/quant/$run_id \
    -t 6 \
    output/amalgkit/pbarbatus/work/fastq/$run_id/${run_id}_1.fastq.gz \
    output/amalgkit/pbarbatus/work/fastq/$run_id/${run_id}_2.fastq.gz
  
  # 3. Delete FASTQ immediately
  rm -rf output/amalgkit/pbarbatus/work/fastq/$run_id
  
  echo "✅ $run_id complete"
done
```

### Method 3: Using Amalgkit Config

Use the existing configuration file:

```bash
cd /Users/4d/Documents/GitHub/metainformant

# Run full pipeline
PYTHONPATH=src python3 << 'EOF'
from metainformant.rna import amalgkit
from pathlib import Path

config_dir = Path("output/amalgkit/pbarbatus")
work_dir = config_dir / "work"

# Download remaining samples
params = {
    "out_dir": str(work_dir),
    "threads": 6,
}

print("Downloading remaining samples...")
amalgkit.getfastq(
    params,
    work_dir=str(config_dir),
    log_dir=str(config_dir / "logs"),
    check=False
)

# Quantify with auto-cleanup
params["clean_fastq"] = "yes"  # Auto-delete FASTQs after successful quant
print("Quantifying samples...")
amalgkit.quant(
    params,
    work_dir=str(config_dir),
    log_dir=str(config_dir / "logs"),
    check=False
)

print("✅ Processing complete!")
EOF
```

---

## 📈 After All Samples Quantified

### Merge into Expression Matrix

```bash
cd /Users/4d/Documents/GitHub/metainformant

PYTHONPATH=src python3 << 'EOF'
from metainformant.rna import amalgkit
from pathlib import Path

config_dir = Path("output/amalgkit/pbarbatus")
work_dir = config_dir / "work"

# Merge all abundance.tsv files
params = {
    "out_dir": str(work_dir),
    "threads": 6,
}

print("Merging all samples...")
amalgkit.merge(
    params,
    work_dir=str(config_dir),
    log_dir=str(config_dir / "logs"),
    check=False
)

print("✅ Expression matrix created!")
print(f"   Location: {work_dir}/merged/merged_abundance.tsv")
print(f"   Format: 20,672 transcripts × 83 samples")
EOF
```

This will create:
```
output/amalgkit/pbarbatus/merged/merged_abundance.tsv
```

**Format**: One row per transcript, one column per sample, TPM-normalized values

---

## 📊 Accessing Expression Data

### Load Individual Samples

```python
import pandas as pd
from pathlib import Path

base = Path("output/amalgkit/pbarbatus/work/quant")

# Load one sample
df = pd.read_csv(base / "SRR14740487" / "abundance.tsv", sep='\t')

# Columns: target_id, length, eff_length, est_counts, tpm
# Use 'tpm' for expression comparisons
```

### Load Merged Matrix (After All Samples)

```python
import pandas as pd

# Load merged expression matrix
expr = pd.read_csv(
    "output/amalgkit/pbarbatus/merged/merged_abundance.tsv",
    sep='\t',
    index_col=0  # transcript_id as index
)

# Shape: (20672 transcripts, 83 samples)
print(expr.shape)

# Filter expressed genes (TPM > 1 in at least 10% of samples)
min_samples = int(0.1 * expr.shape[1])
expressed = expr[(expr > 1).sum(axis=1) >= min_samples]
```

---

## 💾 Storage Management

### Current Usage
```
Total directory:     599MB
├── Metadata:        ~1MB
├── Genome:          ~520MB
├── Index:           20.3MB
├── Transcriptome:   51.3MB
├── Quantification:  2.2MB (2 samples × ~1MB)
└── Logs:            ~5MB
```

### After All 83 Samples
```
Expected total:      ~690MB
├── Metadata:        ~1MB
├── Genome:          ~520MB
├── Index:           20.3MB
├── Transcriptome:   51.3MB
├── Quantification:  ~90MB (83 samples × ~1MB)
├── Merged matrix:   ~5MB
└── Logs:            ~10MB

FASTQ files:         0MB (deleted after quantification)
```

**Key Point**: FASTQs are deleted immediately after each successful quantification, keeping storage minimal.

---

## 🔬 Quality Metrics

### Mapping Rates
- **Target**: >60% mapping rate
- **Achieved**: 64.6-65.8% (excellent)

### Expression Rates
- **Target**: >80% of transcripts detected
- **Achieved**: 89.9-90.6% (excellent)

### Library Quality
- **Fragment length**: 234.9-236.7bp (consistent)
- **Read depth**: 26-27M reads per sample (good)

---

## 📝 Key Files Reference

### Metadata
```
output/amalgkit/pbarbatus/work/metadata/metadata.tsv
- 83 samples from NCBI SRA
- Columns: run_accession, scientific_name, tissue, etc.
```

### Kallisto Index
```
output/amalgkit/pbarbatus/work/index/Pogonomyrmex_barbatus.idx
- Pre-built, ready for quantification
- 20,672 transcripts indexed
- K-mer length: 31
```

### Expression Values
```
output/amalgkit/pbarbatus/work/quant/{sample_id}/abundance.tsv
- Per-sample gene expression
- Columns: target_id, length, eff_length, est_counts, tpm
- Use TPM for normalized expression
```

### Merged Matrix (after completion)
```
output/amalgkit/pbarbatus/merged/merged_abundance.tsv
- All samples in one matrix
- 20,672 rows (transcripts) × 83 columns (samples)
- TPM-normalized values
```

---

## 🎯 Workflow Summary

```
1. ✅ Metadata Discovery       [COMPLETE] 83 samples found
2. ✅ Genome Download          [COMPLETE] Reference genome
3. ✅ Transcriptome Prep       [COMPLETE] 20,672 transcripts
4. ✅ Index Building           [COMPLETE] Kallisto index ready
5. 🔄 Sample Download          [2/83]     Process in batches
6. 🔄 Sample Quantification    [2/83]     Using existing index
7. ⏹️ Merge Expression Matrix  [PENDING]  After all samples
8. ⏹️ Downstream Analysis      [PENDING]  DESeq2, WGCNA, etc.
```

---

## ✅ Consolidated Folder Benefits

1. **Single Source of Truth**: All P. barbatus data in one place
2. **Organized Structure**: Clear hierarchy for all pipeline stages
3. **Reusable Index**: Built once, use for all 83 samples
4. **Efficient Storage**: ~690MB total (vs ~360GB if keeping FASTQs)
5. **Ready to Scale**: Validated workflow for remaining 81 samples

---

**Status**: ✅ **READY FOR BATCH PROCESSING**  
**Next Step**: Download and quantify remaining 81 samples using existing index  
**Estimated Time**: 10-15 hours for all samples (can run overnight)

---

*All variant directories (pbarbatus_direct, _limited, _manual, _simple, _test) have been removed. This is now the single consolidated directory for P. barbatus RNA-seq analysis.*

